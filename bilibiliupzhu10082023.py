# -*- coding: utf-8 -*-
#credits to dadeng and his python: https://github.com/hiDaDeng
#https://textdata.cn/blog/2023-05-07-bilibili-video-info-list/

"""bilibiliUPzhu.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ImTeWULU4gwQUq691aokZIEljYgsbrT7
"""

import requests
import csv
import time


headers = {"user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36"}
template =  'https://api.bilibili.com/x/space/wbi/arc/search?mid={mid}&ps=30&pn={page}'

mid = '495792263'


with open('{mid}_infos.csv'.format(mid=mid), 'w', encoding='utf-8', newline='') as csvf:
    fieldnames = ['comment', 'typeid', 'play', 'pic', 'subtitle', 'description', 'copyright', 'title', 'review', 'author', 'mid', 'created', 'length', 'video_review', 'aid', 'bvid', 'hide_click', 'is_pay', 'is_union_video', 'is_steins_gate', 'is_live_playback', 'meta', 'is_avoided', 'attribute', 'vt_display', 'is_charging_arc', 'vt', 'enable_vt']
    writer = csv.DictWriter(csvf, fieldnames=fieldnames)
    writer.writeheader()
    url = template.format(mid=mid, page=1)
    resp = requests.get(url, headers=headers)
    print(resp.json())
    record_num = resp.json()['data']['page']['count']
    max_page = int(record_num/30)+1
    for page in range(1, max_page+1):
      print('正在爬Up主第 {} 页'.format(page))
      url = template.format(mid=mid, page=page)
      resp = requests.get(url, headers=headers)
      vlist = resp.json()['data']['list']['vlist']
      for video in vlist:
        writer.writerow(video)
time.sleep(10)

import pandas as pd

df = pd.read_csv('495792263_infos.csv')

df.head()

import datetime
df['created'] = df['created'].apply(datetime.datetime.fromtimestamp)
df['created'] = df['created'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))
